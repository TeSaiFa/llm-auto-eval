{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['davinci-003.csv',\n",
       " 'chatglm2.csv',\n",
       " 'chatglm.csv',\n",
       " 'moss-sft.csv',\n",
       " 'chinese-alpaca-13b.csv',\n",
       " 'baichuan-7b.csv',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "os.listdir('dataset/eval_output/review_objective_question')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# accuracy of objective question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'问答': 222, '选择': 140, '判断': 59, '推理': 16, '证明': 6, '应用': 6}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_results = pd.read_csv('dataset/output/results_with_llm.csv')\n",
    "class_tixing = dict(llm_results['题型分类'].value_counts())\n",
    "class_tixing['判断'] = class_tixing['判断']-1 # remove 150 badcase\n",
    "class_tixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc = {}\n",
    "for model in os.listdir('dataset/eval_output/review_objective_question'):\n",
    "    \n",
    "    if 'ipynb_checkpoints' in model:\n",
    "        continue\n",
    "#     print(model)\n",
    "    model_name = model.split('.csv')[0]\n",
    "    dataset = pd.read_csv(os.path.join('dataset/eval_output/review_objective_question/', model)).dropna(axis='columns', how='all')\n",
    "#     print(dataset.columns)\n",
    "    hit_judge, hit_choice = 0, 0\n",
    "    sum_ = 0\n",
    "    for d in dataset.iterrows():\n",
    "        if d[1]['id'] == 150:\n",
    "            continue\n",
    "\n",
    "        sum_ += 1\n",
    "        if d[1]['题型分类'] == '判断':\n",
    "            if d[1]['answer'] == 'FALSE' and d[1]['new_answer'] == 'B':\n",
    "                hit_judge += 1\n",
    "            elif d[1]['answer'] == 'TRUE' and d[1]['new_answer'] == 'A':\n",
    "                hit_judge += 1\n",
    "#             else:\n",
    "#                 print(d[1]['answer'])\n",
    "#                 print(d[1]['ori_answer'])\n",
    "#                 print(d[1]['new_answer'])\n",
    "#                 print('*'*100)\n",
    "        if d[1]['题型分类'] == '选择': \n",
    "            if d[1]['answer'] == d[1]['new_answer']:\n",
    "                hit_choice += 1\n",
    "    acc[model_name] = {\n",
    "        'judgement_acc': hit_judge/class_tixing['判断'],\n",
    "        'choice_acc': hit_choice/class_tixing['选择'],\n",
    "        'objective_acc': (hit_choice+hit_judge)/(class_tixing['判断']+class_tixing['选择'])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'davinci-003': {'judgement_acc': 0.8305084745762712,\n",
       "  'choice_acc': 0.6714285714285714,\n",
       "  'objective_acc': 0.7185929648241206},\n",
       " 'chatglm2': {'judgement_acc': 0.864406779661017,\n",
       "  'choice_acc': 0.5785714285714286,\n",
       "  'objective_acc': 0.6633165829145728},\n",
       " 'chatglm': {'judgement_acc': 0.7457627118644068,\n",
       "  'choice_acc': 0.4357142857142857,\n",
       "  'objective_acc': 0.5276381909547738},\n",
       " 'moss-sft': {'judgement_acc': 0.03389830508474576,\n",
       "  'choice_acc': 0.25,\n",
       "  'objective_acc': 0.18592964824120603},\n",
       " 'chinese-alpaca-13b': {'judgement_acc': 0.2033898305084746,\n",
       "  'choice_acc': 0.45714285714285713,\n",
       "  'objective_acc': 0.38190954773869346},\n",
       " 'baichuan-7b': {'judgement_acc': 0.0847457627118644,\n",
       "  'choice_acc': 0.07857142857142857,\n",
       "  'objective_acc': 0.08040201005025126}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ranking dcg of subjective question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了量化模型答案在数据集上的排序结果，我们引入公式如下：\n",
    "$$score_{ranking}=\\sum_{i=1}^{num}\\frac{frequency_i}{log_2{(i+1)}} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 其中，$score_{ranking}$是一个模型在所有题目上的排序（1-num，第一轮有6个模型和参考答案，排序为1-7）转化为的总分和，衡量了单个模型的主观题目在评测数据集上的表现。\n",
    "- $frequency_i$是模型在整个数据集中得到第$i$名的频率，即$\\frac{sum(rank==i)}{len(dataset)}$\n",
    "- $\\frac{1}{log_2{(i+1)}}$是得到第$i$名赋予的权重（分数）\n",
    "\n",
    "通过对不同名次赋予不同的权重(第一名的得分到第七名依次递减)，用频率进行标准化，最终得到一个排序转化后的分数。\n",
    "需要注意的是，当前排名也包括人工答案，借此可以更好的体现人工答案在候选模型答案中的位置，以及大模型评测对于人工答案的偏好程度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "principle_rank_df = pd.read_csv('dataset/eval_output/subjective_question/principle_ranking_results.csv')\n",
    "model_name = ['chatglm','chatglm2','chinese-alpaca-13b','moss-sft','baichuan-7b', 'davinci-003', 'answer']\n",
    "principle_rank_df = principle_rank_df[principle_rank_df['题型分类'].apply(lambda x: x in ['推理', '证明', '应用', '问答'])]\n",
    "pr_dcg_m = {}\n",
    "for m in model_name:\n",
    "    pr_m_dict = dict(principle_rank_df[m].value_counts())\n",
    "\n",
    "    \n",
    "    pr_dcg = 0\n",
    "    for k,v in pr_m_dict.items():\n",
    "        pr_dcg += (v/len(principle_rank_df))/math.log2(k+1)\n",
    "    pr_dcg_m[m] = pr_dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'judgement_acc': 0.8305084745762712,\n",
       "  'choice_acc': 0.6714285714285714,\n",
       "  'open_qa_dcg': 0.5002372233160524,\n",
       "  'model_name': 'davinci-003'},\n",
       " {'judgement_acc': 0.864406779661017,\n",
       "  'choice_acc': 0.5785714285714286,\n",
       "  'open_qa_dcg': 0.6489089931704489,\n",
       "  'model_name': 'chatglm2'},\n",
       " {'judgement_acc': 0.7457627118644068,\n",
       "  'choice_acc': 0.4357142857142857,\n",
       "  'open_qa_dcg': 0.7230369680042827,\n",
       "  'model_name': 'chatglm'},\n",
       " {'judgement_acc': 0.03389830508474576,\n",
       "  'choice_acc': 0.25,\n",
       "  'open_qa_dcg': 0.4225744782230914,\n",
       "  'model_name': 'moss-sft'},\n",
       " {'judgement_acc': 0.2033898305084746,\n",
       "  'choice_acc': 0.45714285714285713,\n",
       "  'open_qa_dcg': 0.5152436742851731,\n",
       "  'model_name': 'chinese-alpaca-13b'},\n",
       " {'judgement_acc': 0.0847457627118644,\n",
       "  'choice_acc': 0.07857142857142857,\n",
       "  'open_qa_dcg': 0.38780022669896697,\n",
       "  'model_name': 'baichuan-7b'}]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_dcg_results = []\n",
    "for model,dic in acc.items():\n",
    "    dic['open_qa_dcg'] = pr_dcg_m[model]\n",
    "    dic['model_name'] = model\n",
    "    acc_dcg_results.append(dic)\n",
    "acc_dcg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dcg_results.append({\n",
    "    'model_name': 'answer',\n",
    "    'judgement_acc': 1,\n",
    "    'open_qa_dcg': pr_dcg_m['answer'],\n",
    "    'choice_acc': 1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(acc_dcg_results).to_csv('dataset/eval_metrics/acc_dcg_by_question_type.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chatglm': 0.7230369680042827,\n",
       " 'chatglm2': 0.6489089931704489,\n",
       " 'chinese-alpaca-13b': 0.5152436742851731,\n",
       " 'moss-sft': 0.4225744782230914,\n",
       " 'baichuan-7b': 0.38780022669896697,\n",
       " 'davinci-003': 0.5002372233160524,\n",
       " 'answer': 0.4374399135409668}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_dcg_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 dimension scoring of subjective question（有效性/可靠性/流畅性）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pointwise_chatglm.csv',\n",
       " 'pointwise_davinci-003.csv',\n",
       " 'pointwise_chinese-alpaca-13b.csv',\n",
       " 'pointwise_chatglm2.csv',\n",
       " 'pointwise_moss-sft.csv',\n",
       " 'pointwise_baichuan-7b.csv']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = [d for d in os.listdir('dataset/eval_output/subjective_question') if 'pointwise' in d]\n",
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for model in data_list:\n",
    "    sum_ = 0\n",
    "    model_name = model.split('.csv')[0].split('pointwise_')[1]\n",
    "    dataset = pd.read_csv(os.path.join('dataset/evaluation/subjective_question/', model)).dropna(axis='columns', how='all')\n",
    "    effectiveness,reliability,fluency = 0,0,0\n",
    "    for d in dataset.iterrows():\n",
    "        if d[1]['题型分类'] in ['推理', '证明', '应用', '问答']:\n",
    "            sum_ += 1\n",
    "            if isinstance(d[1]['model_answer'], str) and not d[1]['model_answer']:\n",
    "                effectiveness += 1\n",
    "                reliability += 1\n",
    "                fluency += 1\n",
    "            elif isinstance(d[1]['model_answer'], str) and d[1]['model_answer']:\n",
    "                effectiveness += int(d[1]['effectiveness'])\n",
    "                reliability += int(d[1]['reliability'])\n",
    "                fluency += int(d[1]['fluency'])\n",
    "            elif math.isnan(d[1]['model_answer']):\n",
    "                effectiveness += 1\n",
    "                reliability += 1\n",
    "                fluency += 1\n",
    "            else: \n",
    "                effectiveness += int(d[1]['effectiveness'])\n",
    "                reliability += int(d[1]['reliability'])\n",
    "                fluency += int(d[1]['fluency'])\n",
    "\n",
    "\n",
    "    scores[model_name] = {\n",
    "        'effectiveness':effectiveness/sum_,\n",
    "        'reliability':reliability/sum_,\n",
    "        'fluency':fluency/sum_\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chatglm': {'effectiveness': 2.884, 'reliability': 2.8, 'fluency': 2.96},\n",
       " 'davinci-003': {'effectiveness': 2.868, 'reliability': 2.8, 'fluency': 2.988},\n",
       " 'chinese-alpaca-13b': {'effectiveness': 2.492,\n",
       "  'reliability': 2.684,\n",
       "  'fluency': 2.948},\n",
       " 'chatglm2': {'effectiveness': 2.832, 'reliability': 2.748, 'fluency': 2.968},\n",
       " 'moss-sft': {'effectiveness': 1.912, 'reliability': 2.04, 'fluency': 2.544},\n",
       " 'baichuan-7b': {'effectiveness': 1.976,\n",
       "  'reliability': 2.128,\n",
       "  'fluency': 2.404}}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjective_scores = []\n",
    "for model,dic in scores.items():\n",
    "    dic['fullmarks'] = 3.000\n",
    "    dic['model_name'] = model\n",
    "    \n",
    "    subjective_scores.append(dic)\n",
    "pd.DataFrame(subjective_scores).to_csv('dataset/eval_metrics/subjective_question_scores_from_3dimension.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 ability dimension score calculation (基础/中文/专业)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_results = pd.read_csv('dataset/output/results_with_llm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'基础能力': 271, '中文特性': 114, '专业能力': 65}\n",
      "{'百科': 110, '计算能力': 40, '语义理解': 39, '代码': 39, '字义理解': 24, '对话闲聊': 22, '谚语': 22, '生成与创作': 21, '文学': 20, '成语': 19, '医疗': 19, '汉字字形和拼音理解': 18, '翻译': 18, '抽象代数': 16, '法律': 12, '诗文写作': 11}\n"
     ]
    }
   ],
   "source": [
    "sum_per_class_1 = dict(llm_results['一级分类'].value_counts())\n",
    "sum_per_class_2 = dict(llm_results['二级分类'].value_counts())\n",
    "print(sum_per_class_1)\n",
    "print(sum_per_class_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'生成与创作': '基础能力', '语义理解': '基础能力', '百科': '基础能力', '对话闲聊': '基础能力', '计算能力': '基础能力', '代码': '基础能力', '成语': '中文特性', '文学': '中文特性', '谚语': '中文特性', '字义理解': '中文特性', '诗文写作': '中文特性', '汉字字形和拼音理解': '中文特性', '医疗': '专业能力', '翻译': '专业能力', '抽象代数': '专业能力', '法律': '专业能力'}\n"
     ]
    }
   ],
   "source": [
    "class_2_class_1_mapping = {k:v for k,v in zip(llm_results['二级分类'], llm_results['一级分类'])}\n",
    "print(class_2_class_1_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一级分类                                                               基础能力\n",
      "二级分类                                                                 百科\n",
      "domain                                                             自然知识\n",
      "数据来源                                                          机器生成/人工调整\n",
      "题型分类                                                                 判断\n",
      "prompt                                                            答案：对。\n",
      "answer                                                                对\n",
      "id                                                                  150\n",
      "instruction           答案：对。\\n请利用你的自然知识，一步一步思考并从“正确”或者“错误”两个选项中给出最终的判...\n",
      "chatglm               好的,我来解释一下。首先,我们知道,氧气是一种无色、无味、无臭的气体,密度比空气大,在常温下...\n",
      "chatglm2              我认为这个问题的答案是正确的。因为根据我的了解，地球上的生物种类繁多，而且它们之间存在着复杂...\n",
      "chinese-alpaca-13b     1. 水在地球上是循环的吗？\\n2. 水循环包括蒸发、降水和地下水流动吗？\\n3. 水循环...\n",
      "moss-sft              问题：“这个植物是什么花？” <eoh> \\n<|Human|>: 这个超市里的水果都是什么...\n",
      "baichuan-7b            1. The following statements are true or false...\n",
      "davinci-003                                                         正确。\n",
      "Name: 150, dtype: object\n",
      "{'基础能力': 270, '中文特性': 114, '专业能力': 65}\n"
     ]
    }
   ],
   "source": [
    "# bad case remove 150\n",
    "print(llm_results.iloc[150])\n",
    "sum_per_class_1['基础能力'] = sum_per_class_1['基础能力']-1\n",
    "sum_per_class_2['百科'] = sum_per_class_2['百科']-1\n",
    "print(sum_per_class_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_per_class_1 = {\n",
    "    '基础能力': 100,\n",
    "    '中文特性': 100,\n",
    "    '专业能力': 100\n",
    "}\n",
    "\n",
    "\n",
    "score_per_class2_in_different_class1 = {\n",
    "    '基础能力': 100/6,\n",
    "    '中文特性': 100/6,\n",
    "    '专业能力': 100/4\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'生成与创作': 0.7936507936507937,\n",
       " '语义理解': 0.4273504273504274,\n",
       " '百科': 0.15151515151515152,\n",
       " '对话闲聊': 0.7575757575757577,\n",
       " '计算能力': 0.4166666666666667,\n",
       " '代码': 0.4273504273504274,\n",
       " '成语': 0.8771929824561404,\n",
       " '文学': 0.8333333333333334,\n",
       " '谚语': 0.7575757575757577,\n",
       " '字义理解': 0.6944444444444445,\n",
       " '诗文写作': 1.5151515151515154,\n",
       " '汉字字形和拼音理解': 0.925925925925926,\n",
       " '医疗': 1.3157894736842106,\n",
       " '翻译': 1.3888888888888888,\n",
       " '抽象代数': 1.5625,\n",
       " '法律': 2.0833333333333335}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_2_score_per_question = {\n",
    "   c_2:score_per_class2_in_different_class1[c_1]/sum_per_class_2[c_2] for c_2,c_1 in class_2_class_1_mapping.items()\n",
    "    \n",
    "}\n",
    "class_2_score_per_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_2_open_qa_weight_mapping = {\n",
    "    '生成与创作': {'effectiveness': 0.6,\n",
    "                 'fluency': 0.3,\n",
    "                 'reliability': 0.1},\n",
    "    '语义理解': {'effectiveness': 0.4,\n",
    "                'fluency': 0.3,\n",
    "                'reliability': 0.3},\n",
    "    '百科': {'effectiveness': 0.2,\n",
    "            'fluency': 0.1,\n",
    "            'reliability': 0.7},\n",
    "    '对话闲聊': {'effectiveness': 0.4,\n",
    "                'fluency': 0.4,\n",
    "                'reliability': 0.2},\n",
    "    '计算能力': {'effectiveness': 0.2,\n",
    "                'fluency': 0.1,\n",
    "                'reliability': 0.7},\n",
    "    '代码': {'effectiveness': 0.2,\n",
    "            'fluency': 0.1,\n",
    "            'reliability': 0.7},\n",
    "    '成语': {'effectiveness': 0.5,\n",
    "            'fluency': 0.25,\n",
    "            'reliability': 0.25},\n",
    "    '谚语': {'effectiveness': 0.4,\n",
    "            'fluency': 0.4,\n",
    "            'reliability': 0.2},\n",
    "    '字义理解': {'effectiveness': 0.6,\n",
    "                'fluency': 0.2,\n",
    "                'reliability': 0.2},\n",
    "    '诗文写作': {'effectiveness': 0.6,\n",
    "                'fluency': 0.3,\n",
    "                'reliability': 0.1},\n",
    "    '法律': {'effectiveness': 0.3,\n",
    "            'fluency': 0.2,\n",
    "            'reliability': 0.5},\n",
    "    '医疗': {'effectiveness': 0.3,\n",
    "            'fluency': 0.2,\n",
    "            'reliability': 0.5},\n",
    "    '翻译': {'effectiveness': 0.6,\n",
    "            'fluency': 0.3,\n",
    "            'reliability': 0.1},\n",
    "    '抽象代数': {'effectiveness': 0.4,\n",
    "                'fluency': 0.2,\n",
    "                'reliability': 0.4},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name_objective = 'moss-sft.csv'\n",
    "# model_name_subjective = 'pointwise_moss-sft.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['chatglm', 'chatglm2', 'davinci-003', 'chinese-alpaca-13b', 'moss-sft', 'baichuan-7b']\n",
    "model_name_objective_list = [f'{m}.csv' for m in model_list]\n",
    "model_name_subjective_list = [f'pointwise_{m}.csv' for m in model_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "scores_all_c1 = {}\n",
    "scores_all_c2 = {}\n",
    "\n",
    "for model, model_name_objective, model_name_subjective in zip(model_list, model_name_objective_list, model_name_subjective_list):\n",
    "    objective_acc_per_class_2 = defaultdict(int)\n",
    "    dataset = pd.read_csv(os.path.join('dataset/evaluation/review_objective_question/', model_name_objective)).dropna(axis='columns', how='all')\n",
    "    for d in dataset.iterrows():\n",
    "        if d[1]['id'] == 150:\n",
    "            continue\n",
    "\n",
    "        sum_ += 1\n",
    "        if d[1]['题型分类'] == '判断':\n",
    "            if d[1]['answer'] == 'FALSE' and d[1]['new_answer'] == 'B':\n",
    "                objective_acc_per_class_2[d[1]['二级分类']] += 1\n",
    "            elif d[1]['answer'] == 'TRUE' and d[1]['new_answer'] == 'A':\n",
    "                objective_acc_per_class_2[d[1]['二级分类']] += 1\n",
    "    #             else:\n",
    "    #                 print(d[1]['answer'])\n",
    "    #                 print(d[1]['ori_answer'])\n",
    "    #                 print(d[1]['new_answer'])\n",
    "    #                 print('*'*100)\n",
    "        if d[1]['题型分类'] == '选择': \n",
    "            if d[1]['answer'] == d[1]['new_answer']:\n",
    "                objective_acc_per_class_2[d[1]['二级分类']] += 1\n",
    "    objective_scores_per_class_2 = {c_2:class_2_score_per_question[c_2]*hit for c_2,hit in objective_acc_per_class_2.items()}\n",
    "    \n",
    "    \n",
    "    subjective_point_per_class_2 = defaultdict(float)\n",
    "    dataset = pd.read_csv(os.path.join('dataset/evaluation/subjective_question/', model_name_subjective)).dropna(axis='columns', how='all')\n",
    "    for d in dataset.iterrows():\n",
    "        if d[1]['id'] == 150:\n",
    "            continue\n",
    "\n",
    "        if d[1]['题型分类'] in ['推理', '证明', '应用', '问答']:\n",
    "            if isinstance(d[1]['model_answer'], str) and not d[1]['model_answer']:\n",
    "                effectiveness = 1\n",
    "                reliability = 1\n",
    "                fluency = 1\n",
    "            elif isinstance(d[1]['model_answer'], str) and d[1]['model_answer']:\n",
    "                effectiveness = int(d[1]['effectiveness'])\n",
    "                reliability = int(d[1]['reliability'])\n",
    "                fluency = int(d[1]['fluency'])\n",
    "            elif math.isnan(d[1]['model_answer']):\n",
    "                effectiveness = 1\n",
    "                reliability = 1\n",
    "                fluency = 1\n",
    "            else: \n",
    "                effectiveness = int(d[1]['effectiveness'])\n",
    "                reliability = int(d[1]['reliability'])\n",
    "                fluency = int(d[1]['fluency'])\n",
    "            weights = class_2_open_qa_weight_mapping[d[1]['二级分类']]\n",
    "            score = (effectiveness*weights['effectiveness'] + reliability*weights['reliability'] + fluency*weights['fluency'])/3\n",
    "\n",
    "            subjective_point_per_class_2[d[1]['二级分类']] += class_2_score_per_question[d[1]['二级分类']]*score\n",
    "    \n",
    "    scores_c1 = defaultdict(float)\n",
    "    scores_c2 = defaultdict(float)\n",
    "    \n",
    "    for c_2,score in subjective_point_per_class_2.items():\n",
    "        scores_c2[c_2] += score\n",
    "        c_1 = class_2_class_1_mapping[c_2]\n",
    "        scores_c1[c_1] += score\n",
    "    for c_2,score in objective_scores_per_class_2.items():\n",
    "        scores_c2[c_2] += score\n",
    "        c_1 = class_2_class_1_mapping[c_2]\n",
    "        scores_c1[c_1] += score\n",
    "        \n",
    "    scores_all_c1[model] = scores_c1\n",
    "    scores_all_c2[model] = scores_c2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjective_point_per_class_2 = defaultdict(float)\n",
    "dataset = pd.read_csv(os.path.join('dataset/evaluation/subjective_question/', model_name_subjective)).dropna(axis='columns', how='all')\n",
    "for d in dataset.iterrows():\n",
    "    if d[1]['id'] == 150:\n",
    "        continue\n",
    "\n",
    "    if d[1]['题型分类'] in ['推理', '证明', '应用', '问答']:\n",
    "        if isinstance(d[1]['model_answer'], str) and not d[1]['model_answer']:\n",
    "            effectiveness = 1\n",
    "            reliability = 1\n",
    "            fluency = 1\n",
    "        elif isinstance(d[1]['model_answer'], str) and d[1]['model_answer']:\n",
    "            effectiveness = int(d[1]['effectiveness'])\n",
    "            reliability = int(d[1]['reliability'])\n",
    "            fluency = int(d[1]['fluency'])\n",
    "        elif math.isnan(d[1]['model_answer']):\n",
    "            effectiveness = 1\n",
    "            reliability = 1\n",
    "            fluency = 1\n",
    "        else: \n",
    "            effectiveness = int(d[1]['effectiveness'])\n",
    "            reliability = int(d[1]['reliability'])\n",
    "            fluency = int(d[1]['fluency'])\n",
    "        weights = class_2_open_qa_weight_mapping[d[1]['二级分类']]\n",
    "        score = (effectiveness*weights['effectiveness'] + reliability*weights['reliability'] + fluency*weights['fluency'])/3\n",
    "        \n",
    "        subjective_point_per_class_2[d[1]['二级分类']] += class_2_score_per_question[d[1]['二级分类']]*score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'语义理解': 1.7094017094017095,\n",
       " '百科': 0.7575757575757576,\n",
       " '计算能力': 0.4166666666666667,\n",
       " '代码': 0.4273504273504274,\n",
       " '汉字字形和拼音理解': 4.62962962962963}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective_scores_per_class_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'语义理解': 0.8547008547008548,\n",
       " '百科': 0.4545454545454546,\n",
       " '计算能力': 0.4166666666666667,\n",
       " '代码': 1.7094017094017095,\n",
       " '成语': 1.7543859649122808,\n",
       " '文学': 2.5,\n",
       " '字义理解': 7.63888888888889,\n",
       " '汉字字形和拼音理解': 5.555555555555556,\n",
       " '翻译': 1.3888888888888888,\n",
       " '抽象代数': 4.6875,\n",
       " '法律': 2.0833333333333335}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective_scores_per_class_2 = {c_2:class_2_score_per_question[c_2]*hit for c_2,hit in objective_acc_per_class_2.items()}\n",
    "objective_scores_per_class_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = defaultdict(float)\n",
    "for c_2,score in subjective_point_per_class_2.items():\n",
    "    c_1 = class_2_class_1_mapping[c_2]\n",
    "    scores[c_1] += score\n",
    "for c_2,score in objective_scores_per_class_2.items():\n",
    "    c_1 = class_2_class_1_mapping[c_2]\n",
    "    scores[c_1] += score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'基础能力': 51.260646760646765,\n",
       "             '中文特性': 42.878123338649665,\n",
       "             '专业能力': 49.234283625731})"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chatglm': defaultdict(float,\n",
       "             {'基础能力': 82.23155085655091,\n",
       "              '中文特性': 66.68328017012229,\n",
       "              '专业能力': 69.51937134502923}),\n",
       " 'chatglm2': defaultdict(float,\n",
       "             {'基础能力': 86.69084619084622,\n",
       "              '中文特性': 73.57168172957648,\n",
       "              '专业能力': 78.42044346978558}),\n",
       " 'davinci-003': defaultdict(float,\n",
       "             {'基础能力': 90.47428034928039,\n",
       "              '中文特性': 75.40315435052278,\n",
       "              '专业能力': 81.80616471734893}),\n",
       " 'chinese-alpaca-13b': defaultdict(float,\n",
       "             {'基础能力': 70.68259518259521,\n",
       "              '中文特性': 62.17326776537304,\n",
       "              '专业能力': 63.63913255360624}),\n",
       " 'baichuan-7b': defaultdict(float,\n",
       "             {'基础能力': 46.209817959817954,\n",
       "              '中文特性': 33.32912457912458,\n",
       "              '专业能力': 42.637670565302145}),\n",
       " 'moss-sft': defaultdict(float,\n",
       "             {'基础能力': 51.260646760646765,\n",
       "              '中文特性': 42.878123338649665,\n",
       "              '专业能力': 49.234283625731})}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_all_c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_record = []\n",
    "for model,dic in scores_all_c1.items():\n",
    "    dic['model_name'] = model\n",
    "    c1_record.append(dic\n",
    "    )\n",
    "pd.DataFrame(c1_record).to_csv('dataset/eval_metrics/class_1_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_record = []\n",
    "for model,dic in scores_all_c2.items():\n",
    "    dic['model_name'] = model\n",
    "    c2_record.append(dic\n",
    "    )\n",
    "pd.DataFrame(c2_record).to_csv('dataset/eval_metrics/class_2_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218.43420237170244"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(list(scores_all_c1['chatglm'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_record_normalized = []\n",
    "for model,dic in scores_all_c2.items():\n",
    "    normalized_dic = {'model_name': model}\n",
    "    for c2,score in dic.items():\n",
    "        if c2 != 'model_name':\n",
    "            c1 = class_2_class_1_mapping[c2]\n",
    "            devide = score_per_class2_in_different_class1[c1]\n",
    "            score = score*100/devide\n",
    "            normalized_dic[c2] = score\n",
    "\n",
    "    c2_record_normalized.append(normalized_dic)\n",
    "pd.DataFrame(c2_record_normalized).to_csv('dataset/eval_metrics/class_2_score_normalized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chatglm': defaultdict(float,\n",
       "             {'生成与创作': 16.507936507936513,\n",
       "              '语义理解': 12.678062678062684,\n",
       "              '百科': 15.6868686868687,\n",
       "              '对话闲聊': 15.505050505050512,\n",
       "              '计算能力': 9.375,\n",
       "              '代码': 12.47863247863248,\n",
       "              '谚语': 16.616161616161623,\n",
       "              '字义理解': 4.6759259259259265,\n",
       "              '诗文写作': 16.565656565656568,\n",
       "              '医疗': 23.859649122807017,\n",
       "              '翻译': 11.527777777777775,\n",
       "              '抽象代数': 13.645833333333334,\n",
       "              '法律': 20.48611111111111,\n",
       "              '成语': 6.140350877192983,\n",
       "              '文学': 12.5,\n",
       "              '汉字字形和拼音理解': 10.185185185185187,\n",
       "              'model_name': 'chatglm'}),\n",
       " 'chatglm2': defaultdict(float,\n",
       "             {'生成与创作': 16.45502645502646,\n",
       "              '语义理解': 12.692307692307697,\n",
       "              '百科': 15.2878787878788,\n",
       "              '对话闲聊': 15.606060606060613,\n",
       "              '计算能力': 12.333333333333334,\n",
       "              '代码': 14.31623931623932,\n",
       "              '谚语': 16.515151515151523,\n",
       "              '字义理解': 9.537037037037038,\n",
       "              '诗文写作': 16.666666666666668,\n",
       "              '医疗': 21.973684210526322,\n",
       "              '翻译': 19.120370370370367,\n",
       "              '抽象代数': 13.020833333333336,\n",
       "              '法律': 24.305555555555557,\n",
       "              '成语': 9.649122807017545,\n",
       "              '文学': 9.166666666666668,\n",
       "              '汉字字形和拼音理解': 12.037037037037038,\n",
       "              'model_name': 'chatglm2'}),\n",
       " 'davinci-003': defaultdict(float,\n",
       "             {'生成与创作': 16.03174603174604,\n",
       "              '语义理解': 13.90313390313391,\n",
       "              '百科': 15.050505050505059,\n",
       "              '对话闲聊': 15.606060606060613,\n",
       "              '计算能力': 15.125,\n",
       "              '代码': 14.757834757834761,\n",
       "              '谚语': 16.56565656565657,\n",
       "              '字义理解': 12.314814814814817,\n",
       "              '诗文写作': 16.313131313131315,\n",
       "              '医疗': 22.28070175438597,\n",
       "              '翻译': 21.435185185185183,\n",
       "              '抽象代数': 15.520833333333334,\n",
       "              '法律': 22.569444444444446,\n",
       "              '成语': 7.894736842105264,\n",
       "              '文学': 7.5,\n",
       "              '汉字字形和拼音理解': 14.814814814814817,\n",
       "              'model_name': 'davinci-003'}),\n",
       " 'chinese-alpaca-13b': defaultdict(float,\n",
       "             {'生成与创作': 14.444444444444445,\n",
       "              '语义理解': 12.207977207977212,\n",
       "              '百科': 12.348484848484858,\n",
       "              '对话闲聊': 14.949494949494957,\n",
       "              '计算能力': 4.666666666666667,\n",
       "              '代码': 12.065527065527068,\n",
       "              '谚语': 14.898989898989907,\n",
       "              '字义理解': 5.601851851851853,\n",
       "              '诗文写作': 13.636363636363638,\n",
       "              '医疗': 19.912280701754387,\n",
       "              '翻译': 14.907407407407407,\n",
       "              '抽象代数': 9.166666666666668,\n",
       "              '法律': 19.652777777777782,\n",
       "              '成语': 7.017543859649123,\n",
       "              '文学': 10.833333333333334,\n",
       "              '汉字字形和拼音理解': 10.185185185185187,\n",
       "              'model_name': 'chinese-alpaca-13b'}),\n",
       " 'baichuan-7b': defaultdict(float,\n",
       "             {'生成与创作': 9.417989417989416,\n",
       "              '语义理解': 8.190883190883191,\n",
       "              '百科': 10.222222222222218,\n",
       "              '对话闲聊': 11.262626262626267,\n",
       "              '计算能力': 2.472222222222222,\n",
       "              '代码': 4.6438746438746445,\n",
       "              '谚语': 15.757575757575763,\n",
       "              '字义理解': 1.5277777777777781,\n",
       "              '诗文写作': 11.414141414141415,\n",
       "              '医疗': 17.10526315789474,\n",
       "              '翻译': 6.018518518518517,\n",
       "              '抽象代数': 4.166666666666666,\n",
       "              '法律': 15.347222222222225,\n",
       "              '汉字字形和拼音理解': 4.62962962962963,\n",
       "              'model_name': 'baichuan-7b'}),\n",
       " 'moss-sft': defaultdict(float,\n",
       "             {'生成与创作': 14.047619047619051,\n",
       "              '语义理解': 7.307692307692308,\n",
       "              '百科': 9.71212121212121,\n",
       "              '对话闲聊': 12.626262626262632,\n",
       "              '计算能力': 2.6666666666666665,\n",
       "              '代码': 4.900284900284901,\n",
       "              '谚语': 11.111111111111116,\n",
       "              '字义理解': 9.583333333333336,\n",
       "              '诗文写作': 12.373737373737375,\n",
       "              '医疗': 18.991228070175442,\n",
       "              '翻译': 6.527777777777777,\n",
       "              '抽象代数': 7.604166666666666,\n",
       "              '法律': 16.111111111111114,\n",
       "              '成语': 1.7543859649122808,\n",
       "              '文学': 2.5,\n",
       "              '汉字字形和拼音理解': 5.555555555555556,\n",
       "              'model_name': 'moss-sft'})}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_all_c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
